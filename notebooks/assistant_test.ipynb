{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph Assistant Configuration Demo via the SDK\n",
    "This code demonstrates how to:\n",
    "1. Create a new configuration of an assistant\n",
    "2. Use (invoke) that assistant with a silly question\n",
    "3. Update the assistant's configuration\n",
    "\n",
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---- SETUP ----\n",
    "# Replace with your deployed LangGraph API URL and API key\n",
    "DEPLOYMENT_URL = os.getenv(\"DEPLOYMENT_URL\")  # e.g. \"http://localhost:2024\" or your cloud URL\n",
    "API_KEY = os.getenv(\"API_KEY\")  # If using deployed graph\n",
    "GRAPH_ID = \"agent\"  # Name of the graph, normally set in your langgraph.json file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to our Deployed Agent and Create a New Assistants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Connect to the LangGraph server\n",
    "client = get_client(url=DEPLOYMENT_URL, api_key=API_KEY)\n",
    "\n",
    "# 2. Create a new assistant configuration\n",
    "print(\"Creating a new assistant configuration...\")\n",
    "\n",
    "assistant = await client.assistants.create(\n",
    "    graph_id = GRAPH_ID,\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            \"system_prompt\": \"You are a helpful AI assistant that can help with research.\",\n",
    "            \"model\": \"anthropic/claude-3-7-sonnet-latest\",\n",
    "            \"selected_tools\": [\"get_todays_date\", \"advanced_research\"]\n",
    "        }\n",
    "    },\n",
    "    name=\"Demo Assistant\"\n",
    ")\n",
    "print(\"Assistant created:\", assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "# 3. Create a new thread for the conversation\n",
    "thread = await client.threads.create()\n",
    "print(\"Thread created:\", thread)\n",
    "# 4. Use the assistant: ask a silly question\n",
    "print(\"Invoking the assistant with a question...\")\n",
    "input_data = {\"messages\": [{\"role\": \"human\", \"content\": \"research the latest news in the art world\"}]}\n",
    "# Stream the response for demonstration\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant[\"assistant_id\"],\n",
    "    input=input_data,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    # Check if the event contains messages from the assistant\n",
    "    if \"call_model\" in event.data and \"messages\" in event.data[\"call_model\"]:\n",
    "        for msg in event.data[\"call_model\"][\"messages\"]:\n",
    "            if msg[\"type\"] == \"ai\":\n",
    "                # Pretty print the AI message\n",
    "                AIMessage(content=msg[\"content\"], name=msg.get(\"name\", \"Assistant\")).pretty_print()\n",
    "            elif msg[\"type\"] == \"tool\":\n",
    "                ToolMessage(content=msg[\"content\"], name=msg.get(\"name\", \"Tool\")).pretty_print()\n",
    "            elif msg[\"type\"] == \"human\":\n",
    "                # Pretty print the human message (if you want)\n",
    "                HumanMessage(content=msg[\"content\"], name=msg.get(\"name\", \"User\")).pretty_print()\n",
    "    else:\n",
    "        # Optionally print other event types for debugging\n",
    "        print(f\"Event: {event.event}\")\n",
    "        print(event.data)\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Update the assistant's configuration (e.g., change the system prompt)\n",
    "print(\"Creating a new version for your assistant..\")\n",
    "updated_assistant = await client.assistants.update(\n",
    "    assistant[\"assistant_id\"],\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            \"model_name\": \"openai/gpt-4.1\",\n",
    "            \"system_prompt\": \"You are a funny assistant who likes to include puns in your responses.\"\n",
    "        }\n",
    "    },\n",
    ")\n",
    "print(\"Assistant updated:\", updated_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Use the updated assistant\n",
    "\n",
    "thread2 = await client.threads.create()\n",
    "print(\"New thread created:\", thread)\n",
    "\n",
    "print(\"Invoking the updated assistant...\")\n",
    "input_data2 = {\"messages\": [{\"role\": \"user\", \"content\": \"If you could be any animal, which one would you be and why?\"}]}\n",
    "async for event in client.runs.stream(\n",
    "    thread2[\"thread_id\"],\n",
    "    updated_assistant[\"assistant_id\"],\n",
    "    input=input_data2,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    if \"call_model\" in event.data and \"messages\" in event.data[\"call_model\"]:\n",
    "        for msg in event.data[\"call_model\"][\"messages\"]:\n",
    "            if msg[\"type\"] == \"ai\":\n",
    "                # Pretty print the AI message\n",
    "                AIMessage(content=msg[\"content\"], name=msg.get(\"name\", \"Assistant\")).pretty_print()\n",
    "            elif msg[\"type\"] == \"tool\":\n",
    "                ToolMessage(content=msg[\"content\"], name=msg.get(\"name\", \"Tool\")).pretty_print()\n",
    "            elif msg[\"type\"] == \"human\":\n",
    "                # Pretty print the human message (if you want)\n",
    "                HumanMessage(content=msg[\"content\"], name=msg.get(\"name\", \"User\")).pretty_print()\n",
    "    else:\n",
    "        # Optionally print other event types for debugging\n",
    "        print(f\"Event: {event.event}\")\n",
    "        print(event.data)\n",
    "        print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 We can also revert to a previous version if we want to\n",
    "await client.assistants.set_latest(assistant['assistant_id'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
